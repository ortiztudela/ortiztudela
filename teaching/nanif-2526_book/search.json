[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NaNif - Functional neuroimaging",
    "section": "",
    "text": "Bienvenidos a Neuroimagen Funcional\nEste libro contiene los materiales para la sesi√≥n del grupo en espa√±ol del curso Neuroanatom√≠a y Neuroimagen Funcional dentro del M√°ster en Neurociencia Cognitiva de la Universidad de Granada. Esta es la segunda parte del curso Neuroanatom√≠a y Neuroimagen Funcional. La primera parte se centra en la anatom√≠a del sistema nervioso humano y, en esta segunda parte, profundizaremos en su din√°mica funcional.\nEl objetivo general de esta segunda parte es proporcionarte una introducci√≥n a las diferentes t√©cnicas utilizadas en la Investigaci√≥n de Neuroimagen Funcional y los tipos de an√°lisis m√°s comunes. En las sesiones pr√°cticas, tendr√°s la oportunidad de implementar varios tipos de t√©cnicas de an√°lisis (m√°s sobre esto en la siguiente secci√≥n). Para comprender completamente estos an√°lisis, necesitar√°s prepararlos y ejecutarlos usando c√≥digo (tanto MATLAB como Python ser√°n v√°lidos). Si a√∫n eres nuevo en esto de la escritura de c√≥digo, no te preocupes, te proporcionaremos suficiente apoyo y recursos. En esta web encontrar√°s todos los materiales, datasets y ejercicios pr√°cticos que necesitar√°s para completar el curso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Neuroimagen Funcional (Grupo en Espa√±ol)</span>"
    ]
  },
  {
    "objectID": "index.html#c√≥mo-usar-este-libro",
    "href": "index.html#c√≥mo-usar-este-libro",
    "title": "NaNif - Functional neuroimaging",
    "section": "C√≥mo Usar Este Libro",
    "text": "C√≥mo Usar Este Libro\nEste libro est√° organizado semana a semana, siguiendo la estructura del curso. Cada cap√≠tulo contiene informaci√≥n sobre lo que se espera para la sesi√≥n de la semana correspondiente. Adem√°s, a lo largo de las semanas encontrar√°s informaci√≥n sobre hitos concretos y c√≥mo entregarlos.\nNavega por los cap√≠tulos usando la barra lateral o los botones de siguiente/anterior en la parte inferior de cada p√°gina.\nSi tienes alguna pregunta o necesitas m√°s aclaraciones sobre el contenido del curso, las tareas o cualquier problema t√©cnico relacionado con los an√°lisis, no dudes en contactar conmigo por correo electr√≥nico o durante las horas de tutor√≠a. Estoy aqu√≠ para apoyar tu proceso de aprendizaje .\nRecuerda, este curso no va solo de aprender aspectos te√≥ricos de la Neurimagen Funcional, sino tambi√©n de aprender a implementar algunos de los an√°lisis m√°s comunes en el campo de una manera pr√°ctica. Te animamos a interactuar activamente con los materiales del curso, a participar en las discusiones durante las sesiones presenciales y aportar tus perspectivas e ideas √∫nicas.\n¬°Buena suerte y esperamos que aprendas mucho!",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Neuroimagen Funcional (Grupo en Espa√±ol)</span>"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Resumen de la asignatura",
    "section": "",
    "text": "Objetivos de la asignatura\nAl completar esta asignatura‚Ä¶",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Resumen de la asignatura</span>"
    ]
  },
  {
    "objectID": "introduction.html#objetivos-de-la-asignatura",
    "href": "introduction.html#objetivos-de-la-asignatura",
    "title": "Resumen de la asignatura",
    "section": "",
    "text": "Tendr√°s una visi√≥n global de las distintas t√©cnicas de neuroimagen funcional.\nTe sentir√°s c√≥mod@ con los distintos tipos de datos de cada t√©cnica.\nSabr√°s aplicar algunos de los an√°lisis m√°s comunes para cada t√©cnica.\nSabr√°s c√≥mo interpretar los resultados obtenidos de cada t√©cnica.\nAdquirir√°s o mejorar√°s tus habilidades de programaci√≥n.",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Resumen de la asignatura</span>"
    ]
  },
  {
    "objectID": "introduction.html#reponsable-de-la-asignatura",
    "href": "introduction.html#reponsable-de-la-asignatura",
    "title": "Resumen de la asignatura",
    "section": "Reponsable de la asignatura",
    "text": "Reponsable de la asignatura\n\nJavier Ortiz Tudela\n\nEmail: ortiztudela@ugr.es\nDespacho: 308 @ CIMCYC\n\n\nNota: Aunque tengo horarios de tutor√≠as, suele ser mejor que me escribas un email con antelaci√≥n y as√≠ me puedo estar preparado para tus preguntas o tus dudas.",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Resumen de la asignatura</span>"
    ]
  },
  {
    "objectID": "before_starting.html",
    "href": "before_starting.html",
    "title": "Antes de comenzar",
    "section": "",
    "text": "Informaci√≥n general\nEsta web ser√° tu material de referencia para el contenido te√≥rico y para todos los ejercicios pr√°cticos del curso. Adem√°s, utilizaremos PRADO para el seguimiento semanal de las actividades y las sesiones presenciales. Subir√© las diapositivas utilizadas a PRADO despu√©s de cada sesi√≥n. Como ya has visto arriba, una parte importante de la asignatura es el tratamiento de datos. Para que esto se haga bien, vamos a utilizar c√≥digo. Si hasta ahora no has tenido experiencia con c√≥digo, no te preocupes, solo necesitas voluntad de aprender, energ√≠a y un poco de paciencia. En el resto de esta secci√≥n vamos a ayudarte a preparar tu ambiente de trabajo para que puedas aprovechar el curso al m√°ximo.\nAunque todo esto parezca mucho trabajo as√≠ de primeras, no temas. Estamos en esto juntos. Y sobre todo, manten la mente abierta, s√∫bete la curiosidad a tope y no tengas miedo de preguntar.",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Antes de comenzar</span>"
    ]
  },
  {
    "objectID": "before_starting.html#informaci√≥n-general",
    "href": "before_starting.html#informaci√≥n-general",
    "title": "Antes de comenzar",
    "section": "",
    "text": "Do not be afraid of code. It is your friend.",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Antes de comenzar</span>"
    ]
  },
  {
    "objectID": "before_starting.html#requisitos-de-hardware-y-software",
    "href": "before_starting.html#requisitos-de-hardware-y-software",
    "title": "Antes de comenzar",
    "section": "Requisitos de hardware y software",
    "text": "Requisitos de hardware y software\nUna de las cosas que s√≠ vas a necesitar es un ordenador medio decente. Este t√©rmino es un poco ambiguo pero por tener una idea general, un equipo con las caracter√≠sticas de aqu√≠ abajo ser√° suficiente. Si no puedes conseguir un equipo as√≠, d√≠melo y encontraremos una soluci√≥n.\n\nAl menos 8GB de RAM (¬øqu√© es la RAM y c√≥mo consultar cu√°nta tiene mi equipo?)\nProcesador de los √∫ltimos 5 a√±os\nAl menos 20GB de espacio libre en el disco duro\nSistema operativo actualizado (Windows 10/11, MacOS o Linux)\n\nAdem√°s, para trabajar con estos datos, vas a necesitar instalar una serie de programas que te indicamos aqu√≠ abajo. Prueba a instalar todos ellos y si tienes alg√∫n problema, contacta conmigo antes del inicio de esta parte de la asignatura. Es importante que le dediques algo de tiempo a preparar tu espacio de trabajo (es decir, tu ordenador y los programas de aqu√≠ abajo) porque esto va a hacer que tu experiencia del curso sea m√°s sencilla y satisfactoria.\n\nITK-Snap (v 4.2.2). Este programa lo utilizaremos para visualizar datos de neuroimagen. Es gratuito y f√°cil de instalar. Puedes descargarlo desde aqu√≠. Aseg√∫rate de descargarlo e instalarlo antes de nuestra primera sesi√≥n pr√°ctica.\nVS Code. Cuando trabajamos con c√≥digo, necesitamos un editor que nos permita escribirlo, verificarlo y ejecutarlo. Si ya has trabajado con alg√∫n editor y te sientes c√≥mod@ con √©l, puedes seguir utiliz√°ndolo. Pero si eres nuev@ con esto del c√≥digo, te recomendamos usar VS Code (Visual Studio Code). Es un editor moderno y muy potente que es compatible con muchos lenguajes de programaci√≥n distintos.\n\nPor favor, intenta instalar estos programas antes del inicio de esta parte de la asignatura. Si tienes problemas, no te preocupes ‚Äî todos hemos pasado por ah√≠. Como primera opci√≥n, prueba a preguntarle a tu chatbot favorito (recuerda que con tu cuenta de la UGR tienes acceso tanto a Copilot de Microsoft como a la versi√≥n segura de Gemini de Google). Si a√∫n as√≠, no consigues avanzar, dedicaremos unos minutos a resolver problemas de instalaci√≥n al final de la primera sesi√≥n.",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Antes de comenzar</span>"
    ]
  },
  {
    "objectID": "before_starting.html#trabajando-con-librer√≠as-dentro-de-vs-code",
    "href": "before_starting.html#trabajando-con-librer√≠as-dentro-de-vs-code",
    "title": "Antes de comenzar",
    "section": "Trabajando con librer√≠as dentro de VS Code",
    "text": "Trabajando con librer√≠as dentro de VS Code\nPara muchos de los an√°lisis que vamos a aprender, nos vamos a apoyar en librer√≠as creadas por la comunidad. Las librer√≠as son onjuntos de c√≥digo ya escrito por otras personas que podemos reutilizar para no tener que empezar desde cero cada vez. Por ejemplo, en lugar de programar nosotros mismos c√≥mo leer un archivo de resonancia magn√©tica, podemos usar una librer√≠a como Nibabel, que ya incluye todas las funciones necesarias para hacerlo. Puedes entender estas librer√≠as como mini-programas que cumplen distintas funciones. En las siguientes l√≠neas te explicamos c√≥mo instalar desde dentro Visual Studio Code todas las librer√≠as que vamos a utilizar en el curso.\n\nAbrir VS Code\n\n\nAbre Visual Studio Code.\nDesde ah√≠ dentro, abre la carpeta del curso en tu ordenador (por ejemplo: NaNif-2526).\n\n\nAbrir una terminal dentro de VS Code\n\n\nEn la barra superior, haz clic en View ‚Üí Terminal (o usa el atajo Ctrl + (Ctrl + acento grave))\nSe abrir√° una ventana en la parte inferior de VS Code. Esa terminal est√° conectada a tu entorno de Python.\n\n\nComprobar que Python est√° disponible\n\n\nEscribe en la terminal:\n\npython --version\n\nüëâ Si aparece algo como Python 3.10.12, todo va bien. Si no, instala Python desde python.org/downloads y reinicia VS Code.\n\n\nCrear un entorno virtual\n\n\nEsto evita conflictos con otras instalaciones de Python. En la terminal escribe:\n\npython -m venv nanif-course\n\nLuego act√≠valo escribiendo:\nWindows:\nnanif-course\\Scripts\\activate\nMac/Linux:\nsource nanif-course/bin/activate\nVer√°s que aparece (nanif-course) al inicio de la l√≠nea en la terminal. ‚úÖ Eso indica que est√°s dentro del entorno virtual.\n\n\nInstalar las librer√≠as necesarias\n\n\nEn la misma terminal, copia y pega esto:\n\npip install nilearn nibabel pandas matplotlib pingouin pathlib mne scipy seaborn sklearn scipy\n\nVerificar instalaci√≥n\n\n\nUna vez termine, prueba en la terminal:\n\npython -c \"import nilearn, nibabel, pandas, matplotlib; print('‚úÖ Todo instalado correctamente')\"\n\nSi ves el mensaje ‚úÖ, ya est√° todo listo.\n\n\n\nüí° Tip final (VS Code)\nUna vez creado el entorno:\n\nAbre el Command Palette (Ctrl+Shift+P o Cmd+Shift+P).\nBusca ‚ÄúPython: Select Interpreter‚Äù.\nElige el que diga algo como Python 3.10 ('nanif-course': venv).\n\nAs√≠ VS Code usar√° ese entorno autom√°ticamente al ejecutar tus scripts.\nEn las pr√≥ximas secciones, comenzamos con los contenidos de la asignatura propiamente. ¬°Adelante!",
    "crumbs": [
      "Introducci√≥n",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Antes de comenzar</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-1.html",
    "href": "sessions/session-1_anatomical-1.html",
    "title": "De anal√≥gico a digital (I)",
    "section": "",
    "text": "¬øQu√© es un esc√°ner anat√≥mico?\nEn la primera parte de la asignatura hab√©is trabajado con maquetas anat√≥micas y con im√°genes en 2D sacadas de un atlas de anatom√≠a. Esta aproximaci√≥n es genial para aprender a identificar los puntos de referencia habituales (p.¬†ej., ventr√≠culos) y a orientarse en el cerebro (es decir, saber d√≥nde est√° qu√© cosa en relaci√≥n a otras cosas). No obstante, cuando realizamos investigaci√≥n con humanos in-vivo, no tenemos acceso directo al cerebro por aquello de que el cerebro est√° encerrado en una caja de hueso -el cr√°neo- (recordad esto porque, aunque suene trivial, ser√° importante m√°s adelante). La soluci√≥n que tenemos, entonces, es usar t√©cnicas indirectas que nos permitan reconstruir lo que sucede dentro del cr√°neo.\nLa t√©cnica m√°s utilizada para acceder a la anatom√≠a del cerebro es la resonancia magn√©tica (RM). Un esc√°ner de RM utiliza un campo magn√©tico muy potente y pulsos de radiofrecuencia para manipular los protones de hidr√≥geno en el agua de los tejidos corporales. Cuando estos protones vuelven a su estado de equilibrio, emiten se√±ales que son captadas por el esc√°ner y convertidas en im√°genes digitales en 2D. Estas im√°genes (llamadas ‚Äúcortes‚Äù o ‚Äúslices‚Äù) luego se combinan para formar una representaci√≥n volum√©trica en 3D del cerebro. La fuerza del campo magn√©tico del esc√°ner, medido en una unidad llamada Tesla, determina varios par√°metros de las im√°genes que se pueden obtener (entre otros, la resoluci√≥n espacial m√°xima); como regla general, cuanto mayor sea el campo magn√©tico, mayor ser√° la resoluci√≥n espacial que podemos alcanzar. El tipo de esc√°ner m√°s com√∫n para investigaci√≥n en NeuroCog, es el de 3 Tesla.\nA diferencia de otras t√©cnicas de imagen indirecta como los rayos X o la tomograf√≠a computarizada (TC), la resonancia magn√©tica: - No utiliza radiaci√≥n ionizante - Ofrece mejor contraste entre los tejidos blandos - Permite visualizar el cerebro desde cualquier √°ngulo - Puede optimizarse para destacar diferentes tipos de tejidos o patolog√≠as\nEsta √∫ltima caracter√≠stica es especialmente interesante. Para recoger sus im√°genes, la MR utiliza una serie de par√°metros que generalmente se conocen como ‚Äúsecuencias‚Äù. Cuando empec√©is a trabajar con MR, oir√©is frecuentemente cosas como ‚Äú¬øqu√© secuencia has utilizado?‚Äù o ‚Äú¬øtienes alguna secuencia para DTI que pueda utilizar?‚Äù. Piensa en esas secuencias como en las recetas que utiliza el esc√°ner para generar sus im√°genes y que contienen todos los par√°metros necesarios. Modificar estos par√°metros nos permite obtener diferentes tipos de im√°genes del cerebro, cada una destacando diferentes aspectos de la anatom√≠a cerebral.\nPor tanto, un ‚Äúesc√°ner anat√≥mico o estructural‚Äù es una secuencia de resonancia magn√©tica (MRI) que proporciona im√°genes detalladas de la anatom√≠a cerebral. Estas im√°genes:\nLas secuencias m√°s comunes son:\nAqu√≠ tienes un ejemplo de imagen estructural T1 de alta resoluci√≥n:\nLa imagen muestra los diferentes contrastes entre materia gris, materia blanca y l√≠quido cefalorraqu√≠deo t√≠picos de una secuencia T1. ¬øQu√© estructuras eres capaz de identificar? ¬øQu√© otras cosas adem√°s del cerebro ves en esta imagen anat√≥mica?",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>De anal√≥gico a digital (I)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-1.html#qu√©-es-un-esc√°ner-anat√≥mico",
    "href": "sessions/session-1_anatomical-1.html#qu√©-es-un-esc√°ner-anat√≥mico",
    "title": "De anal√≥gico a digital (I)",
    "section": "",
    "text": "Nota: El t√©rmino ‚Äúesc√°ner‚Äù se utiliza indistintamente para referirse a la m√°quina que adquiere las im√°genes (p.¬†ej., el esc√°ner est√° encendido) y para referirse a las im√°genes en s√≠ (p.¬†ej., has recogido un escaner anat√≥mico).\n\n\n\n\nIm√°gen del escaner de 3 Tesla del CIMCYC\n\n\n\n\n\n\nTienen alta resoluci√≥n espacial (t√≠picamente 1mm¬≥)\nMuestran excelente contraste entre los diferentes tejidos cerebrales\nSon fundamentales para:\n\nEstudios morfom√©tricos\nAn√°lisis de volumen cerebral\nLocalizaci√≥n precisa de estructuras anat√≥micas\nBase para el registro con im√°genes funcionales\n\n\n\n\nT1: Excelente para ver detalles anat√≥micos (el m√°s com√∫n en investigaci√≥n en NeuroCog)\n\nMateria gris aparece gris oscuro &lt;- ¬°Importante!\nMateria blanca aparece m√°s clara\nL√≠quido cefalorraqu√≠deo (CSF) aparece negro\n\nT2: √ötil para detectar patolog√≠as (poco utilizado en investigaci√≥n no-cl√≠nica)\n\nCSF aparece brillante\nTejido cerebral m√°s oscuro\n\n\n\n\n\n\nEjemplo de imagen T1 anat√≥mica\n\n\n\n\nNota: Como habr√°s notado, los t√©rminos ‚Äúanat√≥mica‚Äù y ‚Äúestructural‚Äù se utilizan de manera intercambiable. En muchas ocasiones, estas im√°genes se denominan simplemente ‚ÄúT1‚Äù.",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>De anal√≥gico a digital (I)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-1.html#tabla-resumen",
    "href": "sessions/session-1_anatomical-1.html#tabla-resumen",
    "title": "De anal√≥gico a digital (I)",
    "section": "Tabla resumen",
    "text": "Tabla resumen\n\n\n\n\n\n\n\nConcepto\nDescripci√≥n\n\n\n\n\nResonancia Magn√©tica (RM)\nT√©cnica que utiliza campo magn√©tico y pulsos de radiofrecuencia para generar im√°genes del cerebro sin radiaci√≥n ionizante\n\n\nSecuencias\nConjunto de par√°metros que determinan c√≥mo se adquieren las im√°genes de RM\n\n\nEsc√°ner anat√≥mico/estructural\nIm√°genes de alta resoluci√≥n (‚âà1mm¬≥) que muestran detalles de la estructura cerebral\n\n\nSecuencia T1\n- Materia gris: gris oscuro- Materia blanca: clara- L√≠quido cefalorraqu√≠deo: negro- Muy com√∫n en investigaci√≥n\n\n\nSecuencia T2\n- L√≠quido cefalorraqu√≠deo: brillante- Tejido cerebral: oscuro- M√°s com√∫n en contextos cl√≠nicos\n\n\nAplicaciones\nEstudios morfom√©tricos, an√°lisis de volumen cerebral, localizaci√≥n de estructuras, base para registro con im√°genes funcionales\n\n\n\nEn la siguiente secci√≥n veremos c√≥mo abrimos e interactuamos con este tipo de im√°genes.",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>De anal√≥gico a digital (I)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-2.html",
    "href": "sessions/session-1_anatomical-2.html",
    "title": "De anal√≥gico a digital (II)",
    "section": "",
    "text": "¬øC√≥mo interact√∫o con im√°genes estructurales?\nLas im√°genes que genera la MR son unos archivos en 3D (como hemos visto en la p√°gina anterior, en realidad son un mont√≥n de im√°genes 2D concatenadas). Al igual que para im√°genes en 2D estar√©is acostumbrados a formatos de archivos como .png, .jpeg o .gif, el formato m√°s com√∫n para im√°genes en 3D se llama Nifti y la extensi√≥n es .nii. Adem√°s, como estos archivos suelen ser grandes, es muy com√∫n (y recomendable) que nos los encontremos comprimidos. Puede que ya hayas trabajado antes con archivos comprimidos en .zip o en .rar (si no sabes qu√© es un archivo comprimido, mira esta web); los archivos de RM suelen comprimirse con Gunzip y la extensi√≥n es .gz. La mayor parte de programas de an√°lisis de este tipo de datos hacen una descompresi√≥n autom√°tica al abrirlos, as√≠ que no tienes que preocuparte por descomprimirlos t√∫. Tanto en esta asignatura como al usar datos que te encuentres por la web, la extensi√≥n m√°s com√∫n para archivos de MR es nii.gz.\nPara visualizar y analizar estas im√°genes, utilizaremos ITK-SNAP, una herramienta de c√≥digo abierto que permite:\nPara abrir un archivo nii.gz, solo tenemos que seleccionarlo, hacer click con el bot√≥n derecho, darle a ‚Äúabrir con‚Ä¶‚Äù y seleccionar ITK-Snap de la lista de programas. Alternativamente, puedes abrir ITK-Snap primero, y pinchar en ‚ÄúOpen image‚Ä¶‚Äù y de ah√≠, buscar el archivo en tu ordenador.\nPrueba a abrir las imagenes que puedes encontrar en esta ruta:\n~/carpeta-en-tu-ordenador/materiales_nanif/session-1/template_space-mni_res-3_brain.nii.gz.\nUna vez abierta la imagen, puedes explorarla de varias maneras:",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>De anal√≥gico a digital (II)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-2.html#c√≥mo-interact√∫o-con-im√°genes-estructurales",
    "href": "sessions/session-1_anatomical-2.html#c√≥mo-interact√∫o-con-im√°genes-estructurales",
    "title": "De anal√≥gico a digital (II)",
    "section": "",
    "text": "Visualizaci√≥n 3D interactiva\nSegmentaci√≥n manual y semi-autom√°tica\nNavegaci√≥n por cortes anat√≥micos\nAjustes de contraste y brillo\n\n\n\n\n\nInterfaz de ITK-Snap\n\n\n\n\n\n\nNavegaci√≥n b√°sica\n\nVistas ortogonales: ITK-SNAP muestra tres vistas perpendiculares (axial, sagital y coronal) que te permiten explorar el cerebro desde diferentes √°ngulos.\nCursor de navegaci√≥n: El cursor cruzado se mantiene sincronizado en las tres vistas, mostrando la misma ubicaci√≥n desde diferentes perspectivas.\nDesplazamiento: Usa la rueda del rat√≥n para desplazarte por los cortes en la vista activa.\nMover imagen: Alt/Option + rat√≥n te permite desplazar la imagen entera.\nZoom: Ctrl + rueda del rat√≥n (o separar con dos dedos en Mac) te permite acercar o alejar la imagen.\n\n\n\nAjustes de visualizaci√≥n\n\nBrillo y contraste: En el men√∫ ‚ÄúTools‚Äù &gt; ‚ÄúImage Contrast‚Äù (o Ctrl/Cmd + I) puedes modificar estos par√°metros para ver mejor las estructuras cerebrales.\nCentrarte en una vista: Puedes centrar la interfaz del programa en las diferentes vistas pinchando en las letras A, S y C (axial, sagital y coronal) junto a cada ventana; para volver al panel de visualizaci√≥n de las tres vistas, pulsa en el icono con cuatro cuadrantes arriba a la derecha.\n\n\n\nOrientaci√≥n en el espacio\nRecuerda que las im√°genes de MRI siguen convenciones neurol√≥gicas de orientaci√≥n:\n\nIzquierda-Derecha: En las vistas axial y coronal, el lado izquierdo de la imagen corresponde al lado derecho del cerebro.\nAnterior-Posterior: La parte superior de la vista axial es la parte anterior (frontal) del cerebro.\nSuperior-Inferior: En las vistas coronal y sagital, la parte superior de la imagen es la parte superior del cerebro.\n\nDedica un tiempo para familiarizarte con la navegaci√≥n en el espacio 3D y para identificar estructuras anat√≥micas principales como el cuerpo calloso, los ventr√≠culos y la corteza cerebral. ¬øQu√© diferencias ves entre las dos im√°genes? ¬°Vamos a hacer una demo juntos!",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>De anal√≥gico a digital (II)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-2.html#tabla-resumen",
    "href": "sessions/session-1_anatomical-2.html#tabla-resumen",
    "title": "De anal√≥gico a digital (II)",
    "section": "Tabla resumen",
    "text": "Tabla resumen\n\n\n\n\n\n\n\nAspecto\nDetalles\n\n\n\n\nFormato de archivo\nNifti (.nii), com√∫nmente comprimido (.nii.gz)\n\n\nHerramienta\nITK-SNAP (c√≥digo abierto)\n\n\nFuncionalidades\n- Visualizaci√≥n 3D interactiva- Segmentaci√≥n manual/semi-autom√°tica- Navegaci√≥n por cortes- Ajustes de contraste/brillo\n\n\nVistas principales\nAxial, Sagital, Coronal\n\n\nOrientaci√≥n\n- Izquierda/Derecha: convenci√≥n neurol√≥gica- Anterior (frontal)/Posterior- Superior/Inferior\n\n\n\nEn la siguiente secci√≥n aplicar√°s todo esto ¬°a tu propio cerebro!",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>De anal√≥gico a digital (II)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-3.html",
    "href": "sessions/session-1_anatomical-3.html",
    "title": "De anal√≥gico a digital (III)",
    "section": "",
    "text": "Pr√°ctica 1. Localizando hitos en tu propio cerebro\nCr√©ditos a Ana Paqui Palenciano (palencianoap@ugr.es)",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>De anal√≥gico a digital (III)</span>"
    ]
  },
  {
    "objectID": "sessions/session-1_anatomical-3.html#pr√°ctica-1.-localizando-hitos-en-tu-propio-cerebro",
    "href": "sessions/session-1_anatomical-3.html#pr√°ctica-1.-localizando-hitos-en-tu-propio-cerebro",
    "title": "De anal√≥gico a digital (III)",
    "section": "",
    "text": "Preparando las im√°genes brutas (conversi√≥n de DICOM a Nifti)\nCuando las im√°genes de resonancia magn√©tica salen del esc√°ner, suelen venir en un formato llamado DICOM (.dcm). Este formato es √∫til para ciertas cosas pero, en la pr√°ctica, no solemos trabajar con √©l. Como hemos visto en la secci√≥n anterior, nuestro formato estrella es Nifti, as√≠ que el primer paso es convertirlas. Para ello, podemos seguir una de las dos aproximaciones de aqu√≠ abajo. La primera es ideal para hacer este proceso robusto y generalizable a una muestra grande de participantes y la segunda nos vale para una conversi√≥n (sucia) peque√±a y r√°pida: para esta pr√°ctica, elegid la que m√°s os atraiga.\n\nOpci√≥n 1: Conversi√≥n mediante c√≥digo\nEl programa m√°s com√∫n en NeuroCog para esto se llama dcm2niix y para poder utilizarlo tendr√©is que instalarlo en vuestro ordenador. Aqu√≠ abajo ten√©is instrucciones sobre c√≥mo hacer esto en MacOs y Windows.\n\nüíª En Mac\n\nAbre la aplicaci√≥n Terminal (puedes buscarla con Spotlight).\nInstala Homebrew (si no lo tienes) copiando y pegando esto:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nInstala dcm2niix con:\nbrew install dcm2niix\nComprueba que funciona:\ndcm2niix -h\nSi ves el texto de ayuda, ya est√° listo.\n\n\n\n\nü™ü En Windows\n\nEntra en la p√°gina oficial: üëâ https://github.com/rordenlab/dcm2niix/releases\nDescarga el archivo ZIP de la versi√≥n m√°s reciente para Windows (dcm2niix_win.zip).\nDescomprime el ZIP en una carpeta f√°cil de encontrar, por ejemplo: C:\\Program Files\\dcm2niix\nA√±ade esa carpeta a la variable de entorno PATH:\n\nEscribe ‚ÄúEditar las variables de entorno del sistema‚Äù en el buscador de Windows y √°brelo.\nHaz clic en Variables de entorno ‚Üí selecciona Path ‚Üí Editar ‚Üí Nuevo.\nA√±ade:\nC:\\Program Files\\dcm2niix\nAcepta todo.\n\nAbre PowerShell o cmd y escribe:\n\ndcm2niix -h\nSi ves el texto de ayuda, la instalaci√≥n est√° correcta.\nUna vez que lo hayas instalado, ya podr√©is usarlo desde tu terminal del sistema y, por lo tanto, desde tu IDE favorito. Aqu√≠ abajo ten√©is un script de Python para poder realizar esta conversi√≥n.\n  import os\n  import subprocess\n\n  # ==== AJUSTA ESTAS TRES VARIABLES ==========================\n  # Pon aqu√≠ la ruta a la carpeta que contiene tus DICOM (.dcm)\n  dicom_folder = r\"/RUTA/A/TU/CARPETA/CON/DICOMS\"\n\n  # Cambia estos placeholders por tu c√≥digo de sujeto y resoluci√≥n\n  subcode = \"PON_AQUI_TU_SUBCODE\"      # p.ej. \"01\" o \"NaNif01\"\n  resolution = \"PON_AQUI_TU_RESOLUCION\"  # p.ej. \"1mm\"\n  # ===========================================================\n\n  # Carpeta donde se guardar√° el NIfTI (puede ser la misma que la de los DICOM)\n  output_folder = dicom_folder\n\n  # Nombre BIDS del archivo de salida (sin extensi√≥n)\n  bids_name = f\"sub-{subcode}_space-native_res-{resolution}_t1w\"\n\n  # Comando para llamar a dcm2niix\n  # IMPORTANTE: Debes tener dcm2niix instalado y accesible desde la terminal\n  cmd = [\n      \"dcm2niix\",\n      \"-z\", \"y\",              # comprimir en .nii.gz\n      \"-f\", bids_name,        # nombre del archivo de salida (sin extensi√≥n)\n      \"-o\", output_folder,    # carpeta de salida\n      dicom_folder            # carpeta con los DICOM\n  ]\n\n  # Ejecutar la conversi√≥n\n  subprocess.run(cmd, check=True)\n\n  print(\"Conversi√≥n completada. Archivo creado como:\")\n  print(os.path.join(output_folder, bids_name + \".nii.gz\"))\n\n\n\nOpci√≥n 2: Conversi√≥n con interfaz\nITK-SNAP puede abrir carpetas con archivos DICOM y guardar el volumen en formato NIfTI (.nii o .nii.gz), pero no est√° pensado como conversor masivo ni conserva metadatos con la misma precisi√≥n que dcm2niix. Si aun as√≠ quieres hacerlo:\n\nAbre ITK-SNAP.\nVe a File ‚Üí Open Main Image‚Ä¶.\nSelecciona la carpeta que contiene los .dcm (no un archivo suelto).\nEspera a que ITK-SNAP los cargue como un solo volumen.\nLuego elige File ‚Üí Save Image As‚Ä¶ y selecciona formato NIfTI (.nii o .nii.gz).\n\n! Recomendaci√≥n para el futuro: Usa dcm2niix para convertir, y ITK-SNAP para visualizar o segmentar. dcm2niix es el est√°ndar en neuroimagen y asegura compatibilidad con BIDS y software como FSL, SPM o AFNI.\n\n\n\n¬°Ya estamos listos!\nDeber√°s utilizar un software de visualizaci√≥n de im√°genes, preferiblemente, ITK-Snap. Este software tienen la opci√≥n de trazar regiones o lesiones, para poder as√≠ generar m√°scaras que se utilicen en an√°lisis futuros. En este caso, usar√°s esas herramientas para identificar una serie de regiones en tus propias im√°genes anat√≥micas, en concreto, en las im√°genes T1-w.\nA continuaci√≥n tienes la lista de regiones a identificar junto con ejemplos:\n\nVentr√≠culos cerebrales\n(indicando los ventr√≠culos laterales, tercer y cuarto ventr√≠culos, el agujero de Monro y el acueducto de Silvio). \nGanglios basales \nT√°lamo \nHipocampo y am√≠gdala \n\nPara cada apartado de regiones, intenta visualizarlas en dos planos distintos (p.¬†ej., axial, coronal, sagital). ¬øQu√© diferencias notas a simple vista con esas mismas regiones en el cerebro template que hemos abierto antes? ¬øPodr√≠as concluir algo solo con esta comparaci√≥n?\nEn las siguientes sesiones empezaremos a trabajar con c√≥digo (Python) as√≠ que, si hab√©is hecho la conversi√≥n con ITK-Snap, pod√©is aprovechar el tiempo de trabajo aut√≥nomo para realizar el peque√±o ejercicio de arriba que os servir√° de pr√°ctica.",
    "crumbs": [
      "De Anal√≥gico a Digital",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>De anal√≥gico a digital (III)</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html",
    "href": "sessions/session-2_functional-neuroimaging.html",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "",
    "text": "Introducci√≥n a la neuroimagen",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html#introducci√≥n-a-la-neuroimagen",
    "href": "sessions/session-2_functional-neuroimaging.html#introducci√≥n-a-la-neuroimagen",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "",
    "text": "La neuroimagen permite observar el cerebro en funcionamiento sin intervenci√≥n directa.\nSe usa en investigaci√≥n cognitiva, diagn√≥stico cl√≠nico y evaluaci√≥n de intervenciones.\nRetos y limitaciones:\n\nSe√±ales indirectas de la actividad neuronal (e.g., BOLD).\nCostes elevados y log√≠stica compleja.\nArtefactos fisiol√≥gicos y ruido ambiental.\nCompromiso entre resoluci√≥n temporal y espacial.",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html#t√©cnicas-con-alta-resoluci√≥n-temporal",
    "href": "sessions/session-2_functional-neuroimaging.html#t√©cnicas-con-alta-resoluci√≥n-temporal",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "T√©cnicas con alta resoluci√≥n temporal",
    "text": "T√©cnicas con alta resoluci√≥n temporal\n\nEEG\n\nMide la actividad el√©ctrica desde el cuero cabelludo.\nResoluci√≥n temporal en milisegundos.\nDatos: series temporales por canal/electrodo.\nEjemplo: componente N170 para el procesamiento de caras.\n\n\n\nMEA (Microelectrode Arrays)\n\nRegistra directamente la actividad neuronal con electrodos implantados.\nResoluci√≥n temporal muy alta y espacial limitada a la regi√≥n implantada.\nPermite estudiar patrones locales de disparo neuronal.\nLimitado a modelos animales o casos cl√≠nicos espec√≠ficos.\nEjemplo: an√°lisis de actividad en ventanas temporales espec√≠ficas o por bandas de frecuencia.",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html#t√©cnicas-con-alta-resoluci√≥n-espacial",
    "href": "sessions/session-2_functional-neuroimaging.html#t√©cnicas-con-alta-resoluci√≥n-espacial",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "T√©cnicas con alta resoluci√≥n espacial",
    "text": "T√©cnicas con alta resoluci√≥n espacial\n\nfMRI (BOLD)\n\nMide cambios hemodin√°micos asociados a la actividad cerebral.\nResoluci√≥n espacial en mil√≠metros; resoluci√≥n temporal en segundos.\nDatos: vol√∫menes 3D a lo largo del tiempo.\nEjemplo: activaci√≥n de √°reas visuales ante est√≠mulos faciales.\n\n\n\nPET\n\nUsa trazadores radioactivos para estudiar metabolismo cerebral.\nAlta resoluci√≥n espacial, muy baja resoluci√≥n temporal.\nMenos usada en investigaci√≥n cognitiva.",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html#t√©cnicas-que-intentan-combinar-ambas-resoluciones",
    "href": "sessions/session-2_functional-neuroimaging.html#t√©cnicas-que-intentan-combinar-ambas-resoluciones",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "T√©cnicas que intentan combinar ambas resoluciones",
    "text": "T√©cnicas que intentan combinar ambas resoluciones\n\nMEG\n\nRegistra campos magn√©ticos generados por la actividad neuronal.\nAlta resoluci√≥n temporal y espacial moderada.\nMenor distorsi√≥n por el cr√°neo en comparaci√≥n con EEG.\nLimitaciones: coste elevado y disponibilidad reducida.",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html#comparaci√≥n-y-resumen",
    "href": "sessions/session-2_functional-neuroimaging.html#comparaci√≥n-y-resumen",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "Comparaci√≥n y resumen",
    "text": "Comparaci√≥n y resumen\n\n\n\n\n\n\n\n\n\n\n\nT√©cnica\nResoluci√≥n Temporal\nResoluci√≥n Espacial\nInvasividad\nCoste\nTipo de se√±al\n\n\n\n\nEEG\nAlta (ms)\nBaja\nNo\nBajo\nEl√©ctrica\n\n\nMEA\nMuy alta (ms)\nLocal\nS√≠\nMedio\nEl√©ctrica directa\n\n\nMEG\nAlta (ms)\nMedia\nNo\nMuy alto\nMagn√©tica\n\n\nfMRI\nBaja (~2s)\nAlta\nNo\nAlto\nHemodin√°mica\n\n\nPET\nMuy baja (min)\nAlta\nS√≠ (trazador)\nMuy alto\nMetab√≥lica",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-2_functional-neuroimaging.html#preguntas-de-discusi√≥n",
    "href": "sessions/session-2_functional-neuroimaging.html#preguntas-de-discusi√≥n",
    "title": "T√©cnicas de neuroimagen: tiempo vs.¬†espacio",
    "section": "Preguntas de discusi√≥n",
    "text": "Preguntas de discusi√≥n\nDiscute en grupo qu√© t√©cnica ser√≠a m√°s adecuada en cada caso:\n\nTeniendo en cuenta lo que has aprendido hasta ahora en el m√°ster, ¬øcu√°ndo usar√≠as EEG y no fMRI? ¬øY al contrario?\n¬øQu√© t√©cnica utilizar√≠as si quisieras registrar la actividad cerebral durante una conversaci√≥n natural?\nPiensa una pregunta que se pudiera responder tanto con fMRI como con EEG.",
    "crumbs": [
      "T√©nicas de Neuroimagen Funcional",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>T√©cnicas de neuroimagen: tiempo vs. espacio</span>"
    ]
  },
  {
    "objectID": "sessions/session-5_task-based-fmri.html",
    "href": "sessions/session-5_task-based-fmri.html",
    "title": "Functional neuroimaging: Task-based fMRI.",
    "section": "",
    "text": "¬øQu√© es el an√°lisis fMRI basada en tareas?\nLa resonancia magn√©tica funcional (fMRI) permite medir cambios en la oxigenaci√≥n de la sangre (BOLD) asociados a la actividad neuronal. En paradigmas basados en tareas, los participantes realizan una actividad espec√≠fica mientras est√°n en el esc√°ner, lo que permite identificar regiones cerebrales involucradas en distintos procesos cognitivos mediante contrastes entre condiciones experimentales.\n\nCaracter√≠sticas principales del an√°lisis de fMRI por tareas:\n\nDise√±o experimental: Las tareas suelen organizarse en bloques o eventos que se repiten varias veces durante la sesi√≥n.\nModelado del dise√±o: Se construye una matriz de dise√±o que modela los efectos esperados de cada condici√≥n.\nContrastes: Se comparan condiciones para identificar activaciones diferenciales en el cerebro.\nResoluci√≥n espacial: Alta precisi√≥n en la localizaci√≥n de regiones activadas.\n\n\n\n\nEjemplo de contraste de activaci√≥n en fMRI. Fuente original: Savage, H. S., Mulders, P. C., Van Eijndhoven, P. F., Van Oort, J., Tendolkar, I., Vrijsen, J. N., ‚Ä¶ & Marquand, A. F. (2024). Dissecting task-based fMRI activity using normative modelling: an application to the Emotional Face Matching Task. Communications biology, 7(1), 888.\n\n\n\n\n\nAplicaci√≥n en neurociencia cognitiva\nEste tipo de an√°lisis permite, por ejemplo, identificar √°reas especializadas en el reconocimiento facial, la toma de decisiones o el control motor. En este caso, nos interesa localizar dos regiones:\n\n√Årea Fusiforme Facial (FFA): asociada al procesamiento de caras.\nCorteza motora primaria: involucrada en el control de movimientos voluntarios, en este caso la mano que responde.\n\n\n\nDescripci√≥n del dataset\nCada participante realizar√° una tarea de discriminaci√≥n de caras dentro del esc√°ner. En cada ensayo, se mostrar√° una imagen que puede ser una cara o una m√°scara (control visual). La respuesta se emite con la mano izquierda o derecha, seg√∫n la instrucci√≥n del bloque.\n\nEstructura del dataset:\n\nArchivo funcional BOLD (.nii.gz): imagen 4D con la se√±al por voxel y tiempo.\nArchivo de eventos (.tsv o .csv): con informaci√≥n por ensayo:\n\nonset: tiempo de aparici√≥n del est√≠mulo\ntrial_type: face_right, face_left, mask_right o mask_left\nstimulus: face o mask\nresponse_hand: left o right\naccuracy y rt: rendimiento del participante\n\n\n\n\n\nChallenge de la sesi√≥n\nDebes realizar an√°lisis univariados para localizar activaciones funcionales asociadas a dos contrastes:\n\nObjetivos:\n\nFFA: Comparar caras vs.¬†m√°scaras para localizar actividad selectiva para caras.\nCorteza motora: Comparar respuestas hechas con la mano derecha vs.¬†izquierda para observar lateralizaci√≥n motora.\n\n\n\nPasos sugeridos:\n\nCargar los datos.\nCrear matriz de dise√±o con condiciones.\nEstimar modelos y obtener mapas de contraste.\nVisualizar activaciones.\n\n\n\n\nPreguntas clave:\n\n¬øD√≥nde se localiza la FFA en tu cerebro?\n¬øQu√© hemisferio muestra activaci√≥n para cada mano?\n¬øCoinciden tus resultados con lo que esperabas?",
    "crumbs": [
      "Sesiones pr√°cticas",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Functional neuroimaging: Task-based fMRI.</span>"
    ]
  },
  {
    "objectID": "sessions/session-6_functional-connectivity.html",
    "href": "sessions/session-6_functional-connectivity.html",
    "title": "Functional neuroimaging: Functional Connectivity.",
    "section": "",
    "text": "¬øQu√© es la conectividad funcional?\nLa conectividad funcional se refiere a la relaci√≥n temporal entre regiones cerebrales que muestran una actividad sincronizada. A diferencia de otras aproximaciones, como la conectividad estructural (que se basa en conexiones anat√≥micas) o la conectividad efectiva (que implica inferencias causales), la conectividad funcional se basa en correlaciones estad√≠sticas entre las se√±ales recogidas en diferentes regiones cerebrales durante una tarea o en reposo.\nEn fMRI, la conectividad funcional suele calcularse correlacionando las series temporales de activaci√≥n BOLD entre distintas regiones de inter√©s (ROIs). Esta medida permite identificar redes funcionales que se activan conjuntamente, incluso en ausencia de estimulaci√≥n externa directa.\n\nCaracter√≠sticas principales:\n\nROI-to-ROI: Correlaci√≥n entre series temporales promedio de dos regiones espec√≠ficas.\nWhole-brain: Matriz de conectividad completa entre muchas regiones.\nCondicionada a tarea o en reposo: Puede estudiarse durante tareas cognitivas o en estado de reposo.\nEscala temporal: Segundos (limitada por la naturaleza de la se√±al BOLD).\n\n\n\n\nEjemplo de matriz de conectividad funcional\n\n\n\n\n\nEjemplo de uso en neurociencia cognitiva\nImagina que un paciente ha sufrido un ictus que afecta a su capacidad de atenci√≥n. Aunque las regiones frontales y parietales (implicadas en la atenci√≥n) parecen estar anat√≥micamente intactas, la comunicaci√≥n funcional entre ellas puede estar deteriorada. Midiendo la conectividad funcional entre estas regiones podemos detectar disfunciones que no ser√≠an visibles anat√≥micamente.\n\n\nDescripci√≥n del dataset\nEste conjunto de datos simula se√±ales fMRI preprocesadas de sujetos en tres grupos: controles, pacientes agudos, y pacientes cr√≥nicos. A cada sujeto se le ha estimado la actividad promedio (beta) en m√∫ltiples regiones cerebrales (ROIs), y se ha introducido una modulaci√≥n dependiente de la condici√≥n cl√≠nica para alterar la conectividad entre regiones clave implicadas en la atenci√≥n (p.ej., corteza prefrontal y parietal).\n\nEstructura:\n\nGrupos: controls/, patients-acute/, patients-chronic/\nPor sujeto:\n\nfunc/subject_space-mni_res-1_bold.nii.gz: imagen funcional preprocesada\nroi/: m√°scaras de regiones de inter√©s (ROIs)\n\nROI atlas: basado en plantilla MNI, permite extraer series temporales promedio por ROI\nConfounds: Incluye posibles artefactos simulados (p.¬†ej., movimiento)\n\n\n\n\nChallenge de la sesi√≥n\nQueremos comprobar si hay diferencias en la conectividad funcional entre regiones de atenci√≥n entre grupos de pacientes. Usaremos correlaciones entre series temporales de beta-values (betaseries) en dos ROIs de inter√©s.\n\nObjetivos:\n\nExtraer series temporales promedio por ROI en cada sujeto.\nCalcular la conectividad funcional entre regiones predefinidas.\nComparar conectividad entre:\n\nControles vs.¬†pacientes agudos\nPacientes agudos vs.¬†cr√≥nicos\nROIs frontales vs.¬†parietales\n\nRelacionar conectividad con un √≠ndice de d√©ficit atencional simulado.\n\n\n\nPreguntas clave:\n\n¬øEn qu√© grupo se observan alteraciones en la conectividad?\n¬øQu√© regiones est√°n implicadas?\n¬øSe relacionan estas alteraciones con el d√©ficit atencional?",
    "crumbs": [
      "Sesiones pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Functional neuroimaging: Functional Connectivity.</span>"
    ]
  },
  {
    "objectID": "sessions/session-3_erp.html",
    "href": "sessions/session-3_erp.html",
    "title": "Functional neuroimaging: ERPs.",
    "section": "",
    "text": "¬øQu√© es un ERP?\nCuando exponemos a una persona a un est√≠mulo su cerebro produce una se√±al en respuesta que podemos registrar con electrodos (bien en la superficie del cr√°neo -con el EEG-, o dentro de √©l -intracraneal-). Los ERPs (Event-Related Potentials, en ingl√©s, o potenciales relacionados a eventos, en espa√±ol) se obtienen mediante el promediado de m√∫ltiples respuesta de EEG (epochs) que est√°n sincronizados con la presentaci√≥n repetida de un est√≠mulo espec√≠fico -un evento-. Este proceso permite separar la se√±al relacionada con el evento de inter√©s del ‚Äúruido‚Äù de fondo de la actividad cerebral continua.\n\nCaracter√≠sticas principales de los ERPs:\n\nComponentes: Los ERPs se caracterizan por una serie de ‚Äúpicos‚Äù o ‚Äúvalles‚Äù (componentes) que tradicionalmente se asocian con diferentes procesos neurocognitivos.\nLatencia: Tiempo que transcurre desde la presentaci√≥n del est√≠mulo hasta la aparici√≥n de un componente espec√≠fico.\nAmplitud: Magnitud de la respuesta, que refleja la fuerza o intensidad del proceso neural.\nTopograf√≠a: Distribuci√≥n espacial de la actividad en el cuero cabelludo.\n\n\n\n\nRepresentaci√≥n idealizada de un ERP con cinco componentes destacados\n\n\n\n\nInterpretaci√≥n Cognitiva de Componentes de ERPs:\nLa aproximaci√≥n m√°s com√∫n al uso de ERPs en Neurociencia Cognitiva consiste en buscar modulaciones de los componentes de un ERP a trav√©s de alguna variable con relevancia cognitiva. Por ejemplo, imag√≠nate que en una pantalla de ordenador mostramos sucesivamente una secuencia de letras con una duraci√≥n muy breve. Adem√°s, pedimos a nuestros participantes que para cada letra presentada, nos digan su nombren si la han percibido. En esta situaci√≥n, podemos calcular los ERPs promediando todas las respuestas cerebrales a cada letra; esto nos permitir√° caracterizar ese ERP a partir de sus componentes. Si encontramos que alguno de estos componentes (p.¬†ej., la amplitud) es diferente cuando los participantes consiguen nombrar la letra comparado con cuando no lo consiguen, pod√≠amos concluir que ese componente se ve modulado por el proceso cognitivo que corresponda a esa situaci√≥n (p.¬†ej., selecci√≥n atencional).\nLos componentes se suelen nombrar con una letra indicando si son positivos (P) o negativos (N) y la ventana temporal (en milisegundos) en la que se encuentran. Aqu√≠ ten√©is algunos componentes comunes y la interpretaci√≥n cognitiva m√°s habitual: 1. N100: Respuesta sensorial temprana (~100ms) 2. P300: Asociado con la atenci√≥n y actualizaci√≥n del contexto (~300ms) 3. N400: Relacionado con el procesamiento sem√°ntico 4. P600: Vinculado al procesamiento sint√°ctico\nLos ERPs son particularmente valiosos en neurociencia cognitiva por su excelente resoluci√≥n temporal, permitiendo estudiar procesos cognitivos que ocurren en milisegundos.\n\n\n\nPreguntas de discusi√≥n\n\n¬øSe te ocurre alg√∫n problema con la interpretaci√≥n de ‚Äúselecci√≥n atencional‚Äù que hemos hecho arriba?\nPiensa en alguna pregunta que se pudiera responder con ERPs.\n\n\n\nDescripci√≥n del dataset\nEl conjunto de datos simula se√±ales EEG de 64 electrodos recogidas de dos grupos: controles y pacientes, en respuesta a tres tipos de est√≠mulos visuales: caras en posici√≥n normal, caras invertidas, y casas. Se han generado 150 ensayos por sujeto (50 por condici√≥n), y la respuesta cerebral se ha simulado en un intervalo temporal de -100 a 500 ms, centrado en un componente N170.\n\nEstructura:\n\nGrupos: controls/ y patients/ (cada uno con varios sujetos)\nFormato por sujeto:\n\ndata.npy: matriz (150 ensayos, 64 electrodos, 300 tiempos)\nconditions.csv: condici√≥n de cada ensayo (face_upright, face_inverted, house)\n\nElectrodos relevantes: 44 y 52 (electrodos t√≠picos para el N170, t√≠pico de procesamiento de caras)\nSampling rate: ~500 Hz\n\n\n\n\nChallenge de la sesi√≥n\nDebes analizar si el componente N170 est√° presente y modulado por el tipo de est√≠mulo, y si estas modulaciones difieren entre controles y pacientes.\n\nObjetivos:\n\nExtraer los ERPs promediando los ensayos por condici√≥n y sujeto.\nVisualizar el N170 en los electrodos 44 y 52.\nComparar:\n\nCaras vs.¬†casas\nCaras normales vs.¬†invertidas\nDiferencias entre controles y pacientes\n\n\n\n\nPreguntas clave:\n\n¬øD√≥nde y cu√°ndo aparece el N170?\n¬øC√≥mo se modula por la inversi√≥n de caras?\n¬øQu√© diferencias hay entre grupos?\n\n\n\nLectura de referencia",
    "crumbs": [
      "Sesiones pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Functional neuroimaging: ERPs.</span>"
    ]
  },
  {
    "objectID": "sessions/session-4_time-frequency.html",
    "href": "sessions/session-4_time-frequency.html",
    "title": "Functional neuroimaging: Time-frequency Analysis.",
    "section": "",
    "text": "¬øQu√© es un an√°lisis tiempo-frecuencia?\nLas se√±ales cerebrales registradas mediante EEG contienen oscilaciones en diferentes frecuencias que reflejan distintos procesos cognitivos. El an√°lisis tiempo-frecuencia permite estudiar c√≥mo var√≠a la potencia de estas frecuencias a lo largo del tiempo y c√≥mo se relacionan con eventos o condiciones experimentales.\nA diferencia de los ERPs, que se centran en cambios de voltaje promedio, el an√°lisis tiempo-frecuencia captura la din√°mica oscilatoria, permitiendo detectar cambios que no son visibles en los promedios por evento.\n\nCaracter√≠sticas principales del an√°lisis tiempo-frecuencia:\n\nFrecuencias de inter√©s: Las bandas m√°s comunes son alpha (8‚Äì12 Hz), beta (13‚Äì30 Hz) y gamma (30‚Äì50 Hz).\nResoluci√≥n temporal: Se mantiene la dimensi√≥n temporal, lo que permite ver en qu√© momentos se incrementa la potencia de cada banda.\nTransformadas: Se suelen utilizar transformadas como la de Morlet para obtener una representaci√≥n tiempo-frecuencia.\n\n\n\n\nRepresentaci√≥n tiempo-frecuencia de una se√±al EEG\n\n\n\n\nInterpretaci√≥n cognitiva:\nDistintas bandas de frecuencia se han asociado con diferentes funciones:\n\nAlpha: inhibici√≥n cortical, atenci√≥n interna\nBeta: control motor, mantenimiento del estado actual\nGamma: integraci√≥n sensorial, procesos perceptivos complejos\n\n\n\n\nDescripci√≥n del dataset\nEl dataset simula se√±ales EEG de 32 electrodos registradas en una tarea visual. Se han simulado datos para distintos participantes con un intervalo temporal de 2 segundos a 250 Hz.\nCada sujeto est√° asociado a un √≠ndice de recuperaci√≥n, y se espera que la actividad oscilatoria (especialmente en bandas alpha, beta y gamma) prediga este valor.\n\nEstructura:\n\nDirectorio: data/\nFormato por sujeto:\n\nsubjectXX_eeg.npy: se√±al EEG simulada de un solo ensayo (1 x 32 x 500)\nband_power_summary.csv: potencia media por banda y sujeto\nfull-sample_recovery-scores.csv: √≠ndice de recuperaci√≥n por sujeto\n\nSampling rate: 250 Hz\nFrecuencias analizadas: 5‚Äì50 Hz (con Morlet, 6 ciclos)\n\n\n\n\nChallenge de la sesi√≥n\nTu objetivo ser√° evaluar si existe una relaci√≥n entre la potencia oscilatoria en distintas bandas y el √≠ndice de recuperaci√≥n de cada sujeto.\n\nObjetivos:\n\nCalcular la potencia por banda (alpha, beta, gamma) a partir de las se√±ales simuladas.\nRelacionar esa potencia con la variable de recuperaci√≥n.\nVisualizar la relaci√≥n con gr√°ficos de dispersi√≥n por banda.\n\n\n\nPreguntas clave:\n\n¬øQu√© banda se relaciona m√°s con el √≠ndice de recuperaci√≥n?\n¬øCu√°l es la direcci√≥n de esa relaci√≥n?\n¬øQu√© interpretaci√≥n neurofuncional se puede hacer?",
    "crumbs": [
      "Sesiones pr√°cticas",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Functional neuroimaging: Time-frequency Analysis.</span>"
    ]
  },
  {
    "objectID": "sessions/session-7_machine-learning.html",
    "href": "sessions/session-7_machine-learning.html",
    "title": "Functional neuroimaging: Classifiers.",
    "section": "",
    "text": "¬øQu√© es el an√°lisis basado en clasificadores?\nLos clasificadores son modelos de aprendizaje autom√°tico que permiten predecir a qu√© categor√≠a pertenece una observaci√≥n en funci√≥n de sus caracter√≠sticas. En neuroimagen, se usan habitualmente para determinar si la actividad cerebral en un ensayo contiene suficiente informaci√≥n para distinguir entre distintas condiciones experimentales (por ejemplo, si el est√≠mulo visto era rojo o verde).\nEste enfoque se enmarca dentro de lo que se conoce como decodificaci√≥n o an√°lisis multivariado. A diferencia del an√°lisis univariado tradicional (que estudia diferencias medias en cada voxel), los clasificadores aprovechan patrones distribuidos de actividad para identificar informaci√≥n relevante.\n\nCaracter√≠sticas principales:\n\nEntrenamiento y testeo: Se entrena el modelo con un conjunto de datos y se eval√∫a en ensayos nuevos.\nGeneralizaci√≥n: El rendimiento del clasificador refleja cu√°n bien se puede generalizar a datos no vistos.\nSensibilidad multivariada: Detecta patrones sutiles que pueden no ser evidentes univariadamente.\n\n\n\n\nRepresentaci√≥n de un clasificador separando clases\n\n\n\n\n\nEjemplo en neurociencia cognitiva\nImagina que presentamos est√≠mulos visuales que var√≠an en color y forma, y queremos saber si el √°rea visual primaria (V1) contiene informaci√≥n sobre esas caracter√≠sticas. Entrenando clasificadores sobre los patrones de activaci√≥n podemos comprobar si se puede predecir el color o la forma a partir de la se√±al cerebral.\n\n\nDescripci√≥n del dataset\nEl conjunto de datos simula mapas beta estimados a partir de una se√±al BOLD de un √∫nico participante expuesto a 16 est√≠mulos visuales (formas rojas o verdes; c√≠rculos o tri√°ngulos). La actividad se ha estimado voxel a voxel usando un modelo GLM con un enfoque LSS.\n\nEstructura:\n\nbeta_maps.npy: matriz (16 ensayos, 73√ó94√ó76) de mapas beta cerebrales\ntrial_labels.csv: etiquetas de cada ensayo: color (g=verde, r=rojo), forma (c=c√≠rculo, t=tri√°ngulo)\nv1_mask.npy: √≠ndice de 1138 voxeles correspondientes a la corteza visual primaria (V1)\n\n\n\nPropiedades de la tarea:\n\nEst√≠mulos presentados durante 2 segundos\nIntervalos entre ensayos aleatorios entre 3 y 15 segundos\n\n\n\n\nChallenge de la sesi√≥n\nQueremos comprobar si V1 contiene informaci√≥n suficiente para discriminar entre las condiciones experimentales mediante clasificadores.\n\nObjetivos:\n\nExtraer los patrones de activaci√≥n en V1 por ensayo.\nEntrenar clasificadores para predecir:\n\nEl color (rojo vs.¬†verde)\nLa forma (c√≠rculo vs.¬†tri√°ngulo)\n\nComparar el rendimiento para color vs.¬†forma.\nExplorar si los resultados coinciden con an√°lisis univariados.\n\n\n\nPreguntas clave:\n\n¬øPuede el clasificador predecir el color o la forma por encima del azar?\n¬øQu√© condici√≥n (color o forma) se representa mejor en V1?\n¬øC√≥mo se comparan los an√°lisis univariado vs.¬†multivariado?",
    "crumbs": [
      "Sesiones pr√°cticas",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Functional neuroimaging: Classifiers.</span>"
    ]
  },
  {
    "objectID": "sessions/session-8_representational-similarity.html",
    "href": "sessions/session-8_representational-similarity.html",
    "title": "Functional neuroimaging: RSA.",
    "section": "",
    "text": "¬øQu√© es el an√°lisis de similitud representacional (RSA)?\nEl an√°lisis de similitud representacional (RSA) permite estudiar c√≥mo se representa la informaci√≥n en el cerebro comparando patrones de actividad entre condiciones. En lugar de centrarse en la actividad media o en la clasificaci√≥n, RSA analiza la estructura de relaciones entre todos los est√≠mulos.\nLa idea central es construir una matriz de disimilitud (RDM) que capture cu√°n diferentes (o similares) son los patrones cerebrales evocados por distintos est√≠mulos. Esta matriz puede luego compararse con modelos te√≥ricos, comportamentales o con datos de otras modalidades.\n\nCaracter√≠sticas principales:\n\nMultivariado: Considera todos los canales (electrodos, voxeles) conjuntamente.\nBasado en distancias: Mide la (dis)similitud entre patrones de activaci√≥n.\nFlexible: Se puede aplicar a EEG, fMRI, MEG, intracraneal‚Ä¶\n\n\n\n\nEjemplo de RDM\n\n\n\n\n\nEjemplo en neurociencia cognitiva\nSupongamos que presentamos c√≠rculos y tri√°ngulos de diferentes colores. Si los patrones cerebrales se agrupan por color (verde/rojo), esto indica que el sistema nervioso representa el color de manera estructurada. Si se agrupan por forma (c√≠rculo/tri√°ngulo), entonces la forma predomina en la codificaci√≥n.\n\n\nDescripci√≥n del dataset\nEste conjunto de datos simula registros intracraneales con un array de microelectrodos (MEA) en respuesta a 16 est√≠mulos visuales. Los est√≠mulos son formas rojas o verdes (c√≠rculos o tri√°ngulos) presentadas durante 2 segundos. Se registraron 1138 electrodos durante 500 ms por ensayo, con una frecuencia de muestreo de 1000 Hz.\n\nEstructura:\n\nmea_data.npy: matriz (16 ensayos, 1138 electrodos, 500 tiempos)\ntrial_labels.csv: etiquetas de condici√≥n (g=verde, r=rojo, c=c√≠rculo, t=tri√°ngulo)\n\n\n\nPropiedades de la se√±al:\n\nSe√±al simulada con diferencias sensibles al color/forma\nVentana de inter√©s: 100‚Äì300 ms, donde se espera representaci√≥n espec√≠fica\n\n\n\n\nChallenge de la sesi√≥n\nQueremos explorar c√≥mo se representan el color y la forma en la se√±al MEA mediante RSA.\n\nObjetivos:\n\nExtraer la se√±al promedio en la ventana de 100‚Äì300 ms para cada ensayo.\nConstruir la matriz de disimilitud (RDM) entre todos los ensayos.\nVisualizar el RDM y explorar si hay agrupamiento por:\n\nColor (verde vs.¬†rojo)\nForma (c√≠rculo vs.¬†tri√°ngulo)\n\nComparar la RDM obtenida con modelos te√≥ricos de color o forma.\n\n\n\nPreguntas clave:\n\n¬øQu√© caracter√≠stica se representa con m√°s claridad: color o forma?\n¬øQu√© tipo de modelo (color/forma) se ajusta mejor a la RDM cerebral?\n¬øCambia la estructura representacional si se usa otra ventana temporal?",
    "crumbs": [
      "Sesiones pr√°cticas",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Functional neuroimaging: RSA.</span>"
    ]
  }
]